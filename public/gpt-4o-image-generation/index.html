<!DOCTYPE html>
<html lang="en-US">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="http://localhost:1313/favicon.ico" />
<title>GPT-4o Image Generation | Matej Babis</title>
<meta name="title" content="GPT-4o Image Generation" />
<meta name="description" content="Notes:
- &#34;Image Generation for everyone&#34;
- Interesting caveat at the end: [excerpt from the release page showing the abililty to generate images with real people]
New updates [link] to OpenAI&rsquo;s 4o model introduces the ability to output images, extending the existing capability to take images as inputs. This brings OpenAI back to the top players of the image generation field as their previous model DALL-E has now been  lacking behind the top players [https://x.com/ArtificialAnlys/status/1904188980423467472] in the field that include both image generatiion-centered start ups [?] like Reve [link] or corporate rivals such as google Imagen 3 [link]." />
<meta name="keywords" content="" />


<meta property="og:url" content="http://localhost:1313/gpt-4o-image-generation/">
  <meta property="og:site_name" content="Matej Babis">
  <meta property="og:title" content="GPT-4o Image Generation">
  <meta property="og:description" content="Notes: - &#34;Image Generation for everyone&#34; - Interesting caveat at the end: [excerpt from the release page showing the abililty to generate images with real people] New updates [link] to OpenAI’s 4o model introduces the ability to output images, extending the existing capability to take images as inputs. This brings OpenAI back to the top players of the image generation field as their previous model DALL-E has now been lacking behind the top players [https://x.com/ArtificialAnlys/status/1904188980423467472] in the field that include both image generatiion-centered start ups [?] like Reve [link] or corporate rivals such as google Imagen 3 [link].">
  <meta property="og:locale" content="en_US">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-03-26T11:18:39+01:00">
    <meta property="article:modified_time" content="2025-03-26T11:18:39+01:00">




  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="GPT-4o Image Generation">
  <meta name="twitter:description" content="Notes: - &#34;Image Generation for everyone&#34; - Interesting caveat at the end: [excerpt from the release page showing the abililty to generate images with real people] New updates [link] to OpenAI’s 4o model introduces the ability to output images, extending the existing capability to take images as inputs. This brings OpenAI back to the top players of the image generation field as their previous model DALL-E has now been lacking behind the top players [https://x.com/ArtificialAnlys/status/1904188980423467472] in the field that include both image generatiion-centered start ups [?] like Reve [link] or corporate rivals such as google Imagen 3 [link].">




  <meta itemprop="name" content="GPT-4o Image Generation">
  <meta itemprop="description" content="Notes: - &#34;Image Generation for everyone&#34; - Interesting caveat at the end: [excerpt from the release page showing the abililty to generate images with real people] New updates [link] to OpenAI’s 4o model introduces the ability to output images, extending the existing capability to take images as inputs. This brings OpenAI back to the top players of the image generation field as their previous model DALL-E has now been lacking behind the top players [https://x.com/ArtificialAnlys/status/1904188980423467472] in the field that include both image generatiion-centered start ups [?] like Reve [link] or corporate rivals such as google Imagen 3 [link].">
  <meta itemprop="datePublished" content="2025-03-26T11:18:39+01:00">
  <meta itemprop="dateModified" content="2025-03-26T11:18:39+01:00">
  <meta itemprop="wordCount" content="989">
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    font-size: 14px;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
    margin-top: 30px;
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    font-size: 16px;
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  header {
    font-size: 16px;
  }

  footer {
    font-size: 12px;
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: inherit;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: inherit;
      text-decoration:underline;
      text-decoration-color: #ff4f40;
    }

    a:hover {
      background-color: #ff4f40;
      text-decoration: none;
    }

    a:visited {
      color: inherit;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>

  

  
</head>

<body>
  <header><a href="/" class="title">
  <h2>Matej Babis</h2>
</a>
<nav><a href="/">home</a>


<a href="/blog">blog</a>

</nav>
</header>
  <main>

<h1>GPT-4o Image Generation</h1>
<p>
  <i>
    <time datetime='2025-03-26' pubdate>
      26 Mar, 2025
    </time>
  </i>
</p>

<content>
  <pre tabindex="0"><code>Notes:
- &#34;Image Generation for everyone&#34;
- Interesting caveat at the end: [excerpt from the release page showing the abililty to generate images with real people]
</code></pre><p>New updates [link] to OpenAI&rsquo;s 4o model introduces the ability to output images, extending the existing capability to take images as inputs. This brings OpenAI back to the top players of the image generation field as their previous model DALL-E has now been  lacking behind the top players [https://x.com/ArtificialAnlys/status/1904188980423467472] in the field that include both image generatiion-centered start ups [?] like Reve [link] or corporate rivals such as google Imagen 3 [link].</p>
<p>The ability to output images is something I have seen requested many times by customers defining LLM-based projects. Especially among the general public it was often a surprise that models this powerful, able to take audio or image inputs cannot return them altered. OpenAI, with its massive ChatGPT user base now addresses this issue, announcing it will provide the new model verisons to all customers, including the free tier [link].</p>
<p>Impressive image generation models already exist, what Google&rsquo;s or now OpenAI&rsquo;s progress brings to the table, however, is the accessibility: Number of weekly ChatGPT users has surpassed 400M last month [https://www.reuters.com/technology/artificial-intelligence/openais-weekly-active-users-surpass-400-million-2025-02-20/]. Additionally, companies that have started integrating LLMs most likely already have a partnership setup with one of the larger players, which makes experimentation with image generation readily available, as opposed to trying to set up a new contract with a smaller start up.</p>
<p>As somebody who prefers visual examples to text, I was curious about exploring a particular use case for a product that would generate simple diagrams that would guide the reader in steps on how to carry out a task.</p>
<h2 id="example-1-text-to-image-generation">Example 1: Text to Image Generation</h2>
<p>For this simple experiment, I wanted a simple visual output that would clearly demonstrate the tools needed and the step by step instructions. In this instance, I asked for a diagram on how to change a tire.</p>
<p>[image]
(Best of 4)</p>
<p>While still looking a bit cartoony (which can be improved upon by refactoring the prompt), the result here shows not only correctly draws all relevant aspects of the tire-changing process, but also uses the semantic understanding of the task at hand: Correct steps are established, hardly impressive in today&rsquo;s state of LLMs, but they are clearly and sequentially laid out in the image, providing a figure that can describe the task at hand visually using only handful of words.</p>
<h2 id="example-2-text--image-to-image-generation">Example 2: Text + Image to Image Generation</h2>
<p>A slightly different task is to consider a textual prompt of the task and incorporate the result into a picture given. Here I have asked to determine where in the photo &ldquo;lug nuts&rdquo; appear and a request to attach a unique number where they appear.</p>
<p>[original image]
[image]
(Best of 4)</p>
<p>While a toy example, what&rsquo;s demonstrated here is the ability to identify the location of relevant information within an image (and hence understand the content of the photo) in addition to understanding the textual task. What&rsquo;s interesting about this is a novel approach to image generation: using tokens instead of diffusion, basically doing reasoning directly the image. One can do transformations that conserve parts of the original. For instance, changing the background while keeping the subject unchanged. An interesting side-effect I have observed is that this is still not 100% consistent. As you can see in the example above, the output is slighlty altered and brushed up. The logo of the car maker has rotated. I expect that the &ldquo;groundedness&rdquo; will improve with newer iterations of the model and will gradually disapper.</p>
<p>In terms of applications, image reasoning opens up a range of possibilities: For example, the feature can be used as a Q&amp;A tool that combines both identification phase of the problem space, as well as the knowledge base for whatever the user asks to do with it, all addressed in one request. Another example could be converting hand-drawn scribbles into presentation-ready computer graphics.</p>
<hr>
<p>With the size of ChatGPT userbase, the newly-available tooling is already generating many interesting application ideas. I suspect it will not take long to start seeing more and more products leveraging the now easily-accessible image generation &amp; understanding models outside of the start-up space.</p>
<h2 id="side-note">Side-note</h2>
<p>As part of the system card [https://cdn.openai.com/11998be9-5319-4302-bfbf-1167e093f1fb/Native_Image_Generation_System_Card.pdf], OpenAI decided <em>not</em> to block the capability of generating content containing (adult) public figures. Public figures who wish for their depiction not to be generated can opt out of this. Not only am I curious to see if this will begin happening, how will it work in practice and how successful will the requesters be, but also what this capability to generate photo-realistic content of any public figure without their prior consent will result in. The (explore page of Sora)[https://sora.com/explore] which contains trending user-generated material, has many examples of realistic fakes of public figures or suggestive images of women.</p>
<hr>
<ol>
<li>Introduction
•	Brief overview of how you’re using LLMs to popularize tech applications
•	Explanation of why you chose the car tire change as a fun, everyday example</li>
<li>Experiment Part I: Diagram Generation
•	Overview of generating a step-by-step diagram for changing a car tire
•	Discussion of the key components labeled (e.g., jack, lug nuts, spare tire)
•	Reflections on how the visual guide simplifies understanding the procedure</li>
<li>Experiment Part II: Photo Annotation
•	Description of the process of uploading an actual car tire photo
•	How you added information directly into the photo to highlight key areas
•	Comparison between the diagram and the annotated photo in terms of clarity and practical use</li>
<li>Reflections &amp; Insights
•	Informal thoughts on the performance and ease of using LLMs for these tasks
•	The potential for LLMs in everyday DIY and tech applications
•	Any unexpected challenges or pleasant surprises during the process</li>
<li>Conclusion
•	Summary of your findings and overall experience
•	Final thoughts on how such experiments can demystify LLM applications for a broader audience</li>
</ol>

</content>
<p>
  
</p>

  </main>
  <footer>made with <a href="https://github.com/janraasch/hugo-bearblog/">Hugo ʕ•ᴥ•ʔ Bear</a>
</footer>

    
</body>

</html>
